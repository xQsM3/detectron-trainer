{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please run this notebook in multi-ants-tracking conda environment!\n",
    "Import libraries\n",
    "Tutorial: https://blog.roboflow.com/how-to-train-detectron2/\n",
    "https://medium.com/@apofeniaco/training-on-detectron2-with-a-validation-set-and-plot-loss-on-it-to-avoid-overfitting-6449418fbf4e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "** fvcore version of PathManager will be deprecated soon. **\n",
      "** Please migrate to the version in iopath repo. **\n",
      "https://github.com/facebookresearch/iopath \n",
      "\n",
      "** fvcore version of PathManager will be deprecated soon. **\n",
      "** Please migrate to the version in iopath repo. **\n",
      "https://github.com/facebookresearch/iopath \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import os\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "#from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "import tqdm\n",
    "\n",
    "\n",
    "from MyTrainer import MyTrainer\n",
    "from LossEvalHook import LossEvalHook\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "## make sure that the model validates agaisnt the val dataset, which is not defautl in the defaulttrainer class\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "    \n",
    "\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "\n",
    "        if output_folder is None:\n",
    "            os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "            output_folder = \"coco_eval\"\n",
    "\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load JSON dataset into python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dicts ={}\n",
    "import json\n",
    "for d in[\"train\",\"val\"]:\n",
    "    with open('/media/linx123-rtx/Elements/Render/YOLO custom dataset aligned (copy)/'+d+'.json', 'r') as fp:\n",
    "        dataset_dicts[d] = json.load(fp)\n",
    "\n",
    "for d in[\"train\",\"val\"]:\n",
    "    for dic in dataset_dicts[d]:\n",
    "        for anno in dic[\"annotations\"]:\n",
    "            if anno[\"bbox_mode\"] == 0:\n",
    "                anno[\"bbox_mode\"] = BoxModeXYXY_ABS\n",
    "            if anno[\"bbox_mode\"] == 1:\n",
    "                anno[\"bbox_mode\"] = BoxMode.XYWH_ABS\n",
    "            if anno[\"bbox_mode\"] == 2:\n",
    "                anno[\"bbox_mode\"] = BoxMode.XYXY_REL\n",
    "            if anno[\"bbox_mode\"] == 3:\n",
    "                anno[\"bbox_mode\"] = BoxMode.XYWH_REL\n",
    "            if anno[\"bbox_mode\"] == 4:\n",
    "                anno[\"bbox_mode\"] = BoxMode.XYWHA_ABS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register detectron2 custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [\"train\", \"val\"]:\n",
    "    DatasetCatalog.register(\"bumblebee_\" + d, lambda d=d: dataset_dicts[d])\n",
    "    MetadataCatalog.get(\"bumblebee_\" + d).set(thing_classes=[\"bumblebee\"])\n",
    "bumblebee_metadata = MetadataCatalog.get(\"bumblebee_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualizing random imgs of registration for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for d in random.sample(dataset_dicts[\"val\"], 3):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=bumblebee_metadata, scale=0.5)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    cv2.imshow('window',out.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare config and start training\n",
    "commands : https://github.com/facebookresearch/Detectron/blob/master/detectron/core/config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading config /home/linx123-rtx/anaconda3/envs/multi-ants-tracking/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/06 10:35:08 d2.engine.defaults]: \u001b[0mModel:\n",
      "RetinaNet(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelP6P7(\n",
      "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/06 10:35:08 d2.data.build]: \u001b[0mRemoved 88 images with no usable annotations. 11359 images left.\n",
      "\u001b[32m[01/06 10:35:09 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "| bumblebee  | 15624        |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[01/06 10:35:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/06 10:35:09 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/06 10:35:09 d2.data.common]: \u001b[0mSerializing 11359 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/06 10:35:09 d2.data.common]: \u001b[0mSerialized dataset takes 4.13 MiB\n",
      "\u001b[32m[01/06 10:35:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/06 10:35:09 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "| bumblebee  | 3447         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[01/06 10:35:09 d2.data.common]: \u001b[0mSerializing 1323 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/06 10:35:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.59 MiB\n",
      "\u001b[32m[01/06 10:35:10 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[01/06 10:36:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/06 10:36:09 d2.data.common]: \u001b[0mSerializing 1323 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/06 10:36:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.59 MiB\n",
      "##########\n",
      "######\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f0b1c24dc10>\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/06 10:36:09 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[01/06 10:36:09 d2.evaluation.coco_evaluation]: \u001b[0m'bumblebee_val' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/06 10:36:09 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at 'coco_eval/bumblebee_val_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[32m[01/06 10:36:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 1323 images\n",
      "\u001b[32m[01/06 10:36:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/1323. 0.0394 s / img. ETA=0:00:52\n",
      "\u001b[32m[01/06 10:36:14 d2.evaluation.evaluator]: \u001b[0mInference done 137/1323. 0.0390 s / img. ETA=0:00:47\n",
      "\u001b[32m[01/06 10:36:19 d2.evaluation.evaluator]: \u001b[0mInference done 263/1323. 0.0389 s / img. ETA=0:00:42\n",
      "\u001b[32m[01/06 10:36:25 d2.evaluation.evaluator]: \u001b[0mInference done 388/1323. 0.0390 s / img. ETA=0:00:37\n",
      "\u001b[32m[01/06 10:36:30 d2.evaluation.evaluator]: \u001b[0mInference done 514/1323. 0.0390 s / img. ETA=0:00:32\n",
      "\u001b[32m[01/06 10:36:35 d2.evaluation.evaluator]: \u001b[0mInference done 639/1323. 0.0390 s / img. ETA=0:00:27\n",
      "\u001b[32m[01/06 10:36:40 d2.evaluation.evaluator]: \u001b[0mInference done 765/1323. 0.0390 s / img. ETA=0:00:22\n",
      "\u001b[32m[01/06 10:36:45 d2.evaluation.evaluator]: \u001b[0mInference done 890/1323. 0.0390 s / img. ETA=0:00:17\n",
      "\u001b[32m[01/06 10:36:50 d2.evaluation.evaluator]: \u001b[0mInference done 1016/1323. 0.0390 s / img. ETA=0:00:12\n",
      "\u001b[32m[01/06 10:36:55 d2.evaluation.evaluator]: \u001b[0mInference done 1141/1323. 0.0391 s / img. ETA=0:00:07\n",
      "\u001b[32m[01/06 10:37:00 d2.evaluation.evaluator]: \u001b[0mInference done 1263/1323. 0.0392 s / img. ETA=0:00:02\n",
      "\u001b[32m[01/06 10:37:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:52.901849 (0.040138 s / img per device, on 1 devices)\n",
      "\u001b[32m[01/06 10:37:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:51 (0.039180 s / img per device, on 1 devices)\n",
      "\u001b[32m[01/06 10:37:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/06 10:37:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
      "\u001b[32m[01/06 10:37:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.09 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[01/06 10:37:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.001  | 0.000  | 0.007 |  nan  |  nan  |\n",
      "\u001b[32m[01/06 10:37:02 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[01/06 10:37:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[01/06 10:37:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[01/06 10:37:02 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0001,0.0006,0.0000,0.0071,nan,nan\n",
      "\u001b[32m[01/06 10:38:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/06 10:38:01 d2.data.common]: \u001b[0mSerializing 1323 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/06 10:38:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.59 MiB\n",
      "##########\n",
      "######\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f0b1cb29d60>\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/06 10:38:01 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
      "\u001b[32m[01/06 10:38:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 1323 images\n",
      "\u001b[32m[01/06 10:38:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/1323. 0.0391 s / img. ETA=0:00:52\n",
      "\u001b[32m[01/06 10:38:06 d2.evaluation.evaluator]: \u001b[0mInference done 135/1323. 0.0389 s / img. ETA=0:00:48\n",
      "\u001b[32m[01/06 10:38:11 d2.evaluation.evaluator]: \u001b[0mInference done 261/1323. 0.0390 s / img. ETA=0:00:42\n",
      "\u001b[32m[01/06 10:38:16 d2.evaluation.evaluator]: \u001b[0mInference done 387/1323. 0.0390 s / img. ETA=0:00:37\n",
      "\u001b[32m[01/06 10:38:21 d2.evaluation.evaluator]: \u001b[0mInference done 513/1323. 0.0390 s / img. ETA=0:00:32\n",
      "\u001b[32m[01/06 10:38:26 d2.evaluation.evaluator]: \u001b[0mInference done 637/1323. 0.0390 s / img. ETA=0:00:27\n",
      "\u001b[32m[01/06 10:38:31 d2.evaluation.evaluator]: \u001b[0mInference done 763/1323. 0.0389 s / img. ETA=0:00:22\n",
      "\u001b[32m[01/06 10:38:36 d2.evaluation.evaluator]: \u001b[0mInference done 888/1323. 0.0390 s / img. ETA=0:00:17\n",
      "\u001b[32m[01/06 10:38:41 d2.evaluation.evaluator]: \u001b[0mInference done 1014/1323. 0.0390 s / img. ETA=0:00:12\n",
      "\u001b[32m[01/06 10:38:47 d2.evaluation.evaluator]: \u001b[0mInference done 1139/1323. 0.0390 s / img. ETA=0:00:07\n",
      "\u001b[32m[01/06 10:38:52 d2.evaluation.evaluator]: \u001b[0mInference done 1264/1323. 0.0390 s / img. ETA=0:00:02\n",
      "\u001b[32m[01/06 10:38:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:52.920213 (0.040152 s / img per device, on 1 devices)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/06 10:38:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:51 (0.039025 s / img per device, on 1 devices)\n",
      "\u001b[32m[01/06 10:38:54 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/06 10:38:54 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval/coco_instances_results.json\n",
      "\u001b[32m[01/06 10:38:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.27s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.37 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.09 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.023\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.085\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[01/06 10:38:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.339 | 2.258  | 0.006  | 0.905 |  nan  |  nan  |\n",
      "\u001b[32m[01/06 10:38:55 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[01/06 10:38:55 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[01/06 10:38:55 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[01/06 10:38:55 d2.evaluation.testing]: \u001b[0mcopypaste: 0.3392,2.2581,0.0062,0.9050,nan,nan\n",
      "\u001b[32m[01/06 10:38:55 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 19  total_loss: 1.407  loss_cls: 0.5907  loss_box_reg: 0.8226  validation_loss: 1.943  time: 0.3812  data_time: 0.0171  lr: 3.8962e-05  max_mem: 6382M\n"
     ]
    }
   ],
   "source": [
    "#from detectron2.engine import DefaultTrainer\n",
    "\n",
    "def get_N():\n",
    "    N = 0\n",
    "    for img in DatasetCatalog.get(\"bumblebee_train\"):\n",
    "        N+=len(img[\"annotations\"] )\n",
    "    return N\n",
    "\n",
    "\n",
    "# CALCULATE ITERATIONS OUT OF EPOCHS\n",
    "EPOCHS = 10 #epochs\n",
    "BS = 128 #128, batch size (between 2...2^n...512, smaller batch sizes are better suited to smaller learning rates)\n",
    "N = get_N()\n",
    "I = round((N / BS) * EPOCHS) # iterations\n",
    "\n",
    "## LOAD CONFIG\n",
    "cfg = get_cfg()\n",
    "# lookup the config file in /home/linx123-rtx/.local/share/Trash/files/detectron2/configs\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"))\n",
    "## DEFINE DATASET IN CONFIG\n",
    "cfg.DATASETS.TRAIN = ('bumblebee_train',)\n",
    "cfg.DATASETS.TEST = ('bumblebee_val',)\n",
    "cfg.DATASETS.TESTBATCH = ('bumblebee_valbatch',)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "## MODEL\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = BS \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (bumblebee).\n",
    "\n",
    "## SOLVER\n",
    "cfg.SOLVER.BASE_LR = 0.01  # good learning rate is 0.0005 for this case, 0.000015 is to high (common is between 10^-6...1)\n",
    "cfg.SOLVER.LR_POLICY = 'steps_with_decay' #lr smoothly decays from SOLVER.BASE_LR to SOLVER.GAMMA * SOLVER.BASE_LR\n",
    "cfg.SOLVER.GAMMA = 0.1 #0.01\n",
    "cfg.SOLVER.STEPS = [0, I/EPOCHS*5, I/EPOCHS*(16),I/EPOCHS*(32),I/EPOCHS*(96)]\n",
    "#cfg.SOLVER.LRS = [0.01, 0.0001, 0.00001,0.000001] # [0.000075, 0.000005, 0.000001,0.0000005]\n",
    "cfg.SOLVER.WARMUP_ITERS = 500 #reduce effect of early training examples\n",
    "# Start the warm up from SOLVER.BASE_LR * SOLVER.WARM_UP_FACTOR\n",
    "cfg.SOLVER.WARM_UP_FACTOR = 1.0 / 3.0\n",
    "# WARM_UP_METHOD can be either 'constant' or 'linear' (i.e., gradual)\n",
    "cfg.SOLVER.WARM_UP_METHOD = 'linear'\n",
    "cfg.SOLVER.MAX_ITER = I   #adjust up if val mAP is still rising, adjust down if overfit\n",
    "cfg.SOLVER.MOMENTUM = 0.9 # Momentum to use with SGD\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4 # IMS_PER_BATCH = 2 means that in 1 iteration the model sees 2 images\n",
    "\n",
    "## TEST CONFIGS\n",
    "cfg.TEST.EVAL_PERIOD = 10\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = MyTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 8088 (pid 2992), started 9:58:13 ago. (Use '!kill 2992' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-89bd7bc857d308b9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-89bd7bc857d308b9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8088;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Look at training curves in tensorboard:\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir output --host localhost --port 8088\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -i 'PlotTogether.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run network on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 1000000  # set a custom testing threshold\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.4\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "for d in random.sample(dataset_dicts[\"val\"], 3):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=bumblebee_metadata, \n",
    "                   scale=0.5, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imshow(os.path.basename(d[\"file_name\"]),out.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
